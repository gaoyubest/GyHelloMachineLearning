[TOC]
# K-近邻算法（KNN）
**定义**：如果一个样本在特征空间中的k个最相似（即特征空间中最邻近）的样本中的大多数属于某一个类别，则样本也属于这个类别。
**欧式距离**：$ρ = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$
注：KNN需要做标准化处理
## 一、数据处理

Facebook V - Predicting Check Ins 数据下载地址：
https://www.kaggle.com/c/facebook-v-predicting-check-ins/data

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200308011347234.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d1MzA1NTI0MDcz,size_16,color_FFFFFF,t_70)


```python
import pandas as pd
from sklearn.model_selection import train_test_split

def load_data_facebook5(test_size=0.25):
    def deal_time():
        nonlocal data_all
        # 处理时间的数据
        time_value = pd.to_datetime(data_all['time'], unit='s')
        # 日期格式转换成字典格式
        time_value = pd.DatetimeIndex(time_value)
        # 构造一些特征
        data_all['day'] = time_value.day
        data_all['hour'] = time_value.hour
        data_all['minute'] = time_value.minute
        data_all['second'] = time_value.second
        # 把时间戳特征删除，pandas：axis=1 指列
        data_all.drop(['time'], axis=1)

    def filter_place_id(min_times):
        """
        把签到数量少于n个目标位置删除
        """
        nonlocal data_all
         # 统计签到次数
        place_count = data_all.groupby('place_id').count()
        # 筛掉次数小于3的
        after_count_data = place_count[place_count.row_id > min_times]
        # 将索引place_id保存为字段
        after_count_data = after_count_data.reset_index()
        data_all = data_all[data_all['place_id'].isin(after_count_data.place_id)]

    def standard():
        """
        特征工程（标准化）
        :return:
        """
        from sklearn.preprocessing import StandardScaler
        nonlocal data_x, data_y
        # 进行特征工程（标准化）
        std = StandardScaler()
        data_x = std.fit_transform(data_x)

    
    data_all = pd.read_csv(__dir__ + 'facebook5/sample.csv')
    deal_time()
    filter_place_id(min_times=3)

    data_x, data_y = data_all.drop(['place_id'], axis=1), data_all['place_id']
    standard()
    # print(data_x, data_y)

    # 进行数据分割
    return train_test_split(data_x, data_y, test_size=test_size)
```
数据处理代码：
```python
# 缩小数据集范围
DataFrame.query()
# 删除没用的日期数据
DataFrame.drop
# 将签到位置少于n个用户的删除
place_count = data_all.groupby('place_id').count()
tf = place_count[place_count.row_id > 3].reset_index()
data = data[data['place_id'].isin(tf.place_id)]

```

## 二、预测结果
```python
from datasets import load_data_facebook5
from sklearn.neighbors import KNeighborsClassifier

if __name__ == '__main__':
    X_train, X_test, Y_train, Y_test = load_data_facebook5()

    # 进行算法流程，超参数
    knn = KNeighborsClassifier(n_neighbors=5)
    # fit predict score
    knn.fit(X_train, Y_train)
    # 得出预测结果
    Y_predict = knn.predict(X_test)
    print("预测值", Y_predict)
    print("准确率", knn.score(X_test, Y_test))
```


## 三、优缺点 ：
- **优**：简单，易于理解，易于实现，无需估计参数，无需训练
- **缺**：懒惰算法，对测试样本分类时的计算量大，内存开销大；必须指定k值，k值选择不当则分类精度不能保证。（k值取小：容易受异常点影响；k值取很大：容易受k值数量[类别]波动）